## ðŸ¥‘ Solution For Argmax's Search By Ingredients Challenge 
**$$ \arg\max_{r \in \mathcal{G}} \ \mathrm{score}(r) \quad \text{subject to } \I(r) = \text{@v1t3ls0n} $$**

**By [Guy Vitelson](https://www.linkedin.com/in/guyvitelson/)** Â· ðŸ™ [@v1t3ls0n](https://github.com/v1t3ls0n) Â· ðŸ“§ [guyvitelson@gmail.com](mailto:guyvitelson@gmail.com)

---

## ðŸ§­ Project Overview

This project classifies recipes as either:

- **Keto-Friendly** (â‰¤10g net carbs per 100g)
- **Vegan** (strictly plant-based)

We assume **no labeled data is available**, and solve the task using weak supervision, rule-based logic, and machine learning. We go beyond requirements by integrating:

- âœ… USDA FoodData Central for numeric nutritional validation  
- âœ… Six-stage silver labeling with regex + fallback rules  
- âœ… ML model training over sparse text/image features  
- âœ… Ensemble optimization and dynamic voting  
- âœ… CLI + Docker + logging + caching for robust execution  

---

## âš™ï¸ Pipeline Architecture

```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Raw Recipe Dataset  â”‚ (No labels)
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â–¼
Silver Label Generator (rules + USDA)
â–¼
Text Vectorizer (TF-IDF)
â”‚
â”œâ”€â”€â–¶ Optional: Image Embeddings (ResNet-50)
â–¼
Model Training (Text / Image / Hybrid)
â–¼
Top-N Ensemble + Rule Verification
â–¼
Export: Metrics, Plots, Artefacts

````

---

## ðŸ”© Silver Labeling Engine

Our system produces training labels (silver labels) via a **6-stage heuristic**:

| Stage | Description                          | Example                                |
|-------|--------------------------------------|----------------------------------------|
| 1.    | Whitelist (early positive)           | "almond flour" is always keto          |
| 2.    | USDA numeric check (carbs â‰¤ 10g)     | "jackfruit" fails: 23g carbs           |
| 3.    | Regex blacklist                      | Rejects "sugar", "rice"                |
| 4.    | Token combination matching           | "kidney beans" â†’ non-keto              |
| 5.    | ML soft classification (probability) | Learns semantic context                |
| 6.    | Hard override with rules             | Final decision ensures dietary safety  |

> Fallbacks like token simplification (`egg whites` â†’ `egg`) + USDA fuzzy match improve recall.

---

## ðŸ§  ML Models and Ensemble

Text classifiers:

- Logistic Regression (Softmax)
- Naive Bayes
- RidgeClassifier
- SGDClassifier
- Passive-Aggressive

Optional image support:

- Download photos from recipe URLs
- Run ResNet-50 embedding extraction
- Merge with text features for multimodal classification

We tune, score, and rank each model across metrics:

- Accuracy
- Precision, Recall
- F1 Score
- ROC AUC, PR AUC

Then, a dynamic ensemble (`top_n`) builds the optimal blend of models for each task, using weighted soft voting and rule verification.

---

## ðŸ§ª Model Evaluation Results (Sorted by Task â†’ F1 Score)
**Image models trained on ~70K images, all models evaluated on the gold set (ground_truth data)**
### ðŸ¥‘ Keto Models

| ðŸ§  Model         | ðŸŽ¯ Task | âœ… Accuracy | ðŸŽ¯ Precision | ðŸ” Recall | ðŸ† F1-Score | â±ï¸ Time (s) |
|------------------|--------|-------------|--------------|-----------|-------------|-------------|
| ðŸ¤– Softmax_TEXT  | keto   | 0.970       | 0.951        | 0.975     | **0.963**   | 3.6         |
| ðŸ§  Ridge_TEXT    | keto   | 0.970       | 0.951        | 0.975     | **0.963**   | 12.4        |
| âš”ï¸ PA_TEXT       | keto   | 0.970       | 0.951        | 0.975     | **0.963**   | 4.2         |
| ðŸ§ª SGD_TEXT      | keto   | 0.970       | 0.951        | 0.975     | **0.963**   | 0.6         |
| ðŸŒ² RF_IMAGE      | keto   | 0.942       | 0.929        | 0.963     | 0.945       | 111.5       |
| ðŸ§¬ Softmax_BOTH  | keto   | 0.942       | 0.929        | 0.963     | 0.945       | 85.8        |
| ðŸŒŸ LGBM_BOTH     | keto   | 0.942       | 0.929        | 0.963     | 0.945       | 109.1       |
| ðŸ§  TxtImg        | keto   | 0.940       | 0.930        | 0.960     | 0.950       | â€“           |
| ðŸ¦  NB_TEXT       | keto   | 0.960       | 0.950        | 0.950     | 0.950       | 0.3         |
| âš¡ LGBM_IMAGE     | keto   | 0.904       | 0.923        | 0.889     | 0.906       | 87.7        |
| ðŸ NB_BOTH       | keto   | 0.865       | 0.955        | 0.778     | 0.857       | 0.2         |
| ðŸ§  MLP_IMAGE     | keto   | 0.750       | 0.938        | 0.556     | 0.698       | 119.8       |

---

### ðŸŒ± Vegan Models

| ðŸ§  Model         | ðŸŽ¯ Task | âœ… Accuracy | ðŸŽ¯ Precision | ðŸ” Recall | ðŸ† F1-Score | â±ï¸ Time (s) |
|------------------|--------|-------------|--------------|-----------|-------------|-------------|
| ðŸ¤– Softmax_TEXT  | vegan  | 0.980       | 0.975        | 0.975     | **0.975**   | 1.6         |
| âš”ï¸ PA_TEXT       | vegan  | 0.980       | 0.975        | 0.975     | **0.975**   | 4.5         |
| ðŸ§  Ridge_BOTH    | vegan  | 0.981       | 1.000        | 0.964     | **0.982**   | 462.9       |
| âš”ï¸ PA_BOTH       | vegan  | 0.981       | 1.000        | 0.964     | **0.982**   | 25.9        |
| ðŸŒ² RF_IMAGE      | vegan  | 1.000       | 1.000        | 1.000     | **1.000**   | 77.6        |
| ðŸ§¬ Softmax_BOTH  | vegan  | 1.000       | 1.000        | 1.000     | **1.000**   | 73.2        |
| ðŸŒ² RF_BOTH       | vegan  | 1.000       | 1.000        | 1.000     | **1.000**   | 29.0        |
| ðŸŒŸ LGBM_BOTH     | vegan  | 1.000       | 1.000        | 1.000     | **1.000**   | 127.9       |
| ðŸ§  TxtImg        | vegan  | 1.000       | 1.000        | 1.000     | **1.000**   | â€“           |
| ðŸ§  MLP_BOTH      | vegan  | 0.962       | 1.000        | 0.929     | 0.963       | 2515.7      |
| âš¡ LGBM_IMAGE     | vegan  | 0.962       | 1.000        | 0.929     | 0.963       | 54.3        |
| ðŸ§  Ridge_TEXT    | vegan  | 0.970       | 0.974        | 0.950     | 0.962       | 12.2        |
| ðŸ§ª SGD_TEXT      | vegan  | 0.970       | 0.974        | 0.950     | 0.962       | 0.6         |
| ðŸ¦  NB_TEXT       | vegan  | 0.960       | 0.974        | 0.925     | 0.949       | 0.1         |
| ðŸ NB_BOTH       | vegan  | 0.788       | 1.000        | 0.607     | 0.756       | 0.2         |
| ðŸ§  MLP_IMAGE     | vegan  | 0.596       | 1.000        | 0.250     | 0.400       | 100.6       |


## ðŸ§  Key Takeaways from Results

These results demonstrate **exceptionally strong performance**, especially considering:

* The **entire training pipeline is weakly supervised** (no ground-truth labels were available during training).
* The **evaluation set is small** (100 samples, of which only 66 have images), meaning scores can fluctuate due to variance.
* Image-based models were trained on **up to 70,000 images**, yielding significant gains over prior experiments with 700 or 7,000 samples â€” proving the benefit of scale in weak visual learning.
* Text-only models continue to dominate due to high signal in ingredient names, with F1-scores reaching **0.96+**.
* **Vegan models reached perfect classification (F1 = 1.0)** when using image+text ensembles â€” a rare result, highlighting alignment between rules, training data, and real-world gold labels.

âš ï¸ **Important Note:**
All the results above were achieved **before** enabling **dynamic per-row ensemble weight optimization**. The current ensemble logic uses static weightings, yet still delivers top-tier metrics. This strongly suggests that adding dynamic weights based on image/text availability could yield even higher confidence and class-specific reliability.

---

## ðŸ–¥ï¸ CLI Interface

Train, test, classify, or run gold-eval in one line:

```bash
# Train and evaluate on silver + gold
python diet_classifiers.py --train --mode both

# Evaluate only against gold set
python diet_classifiers.py --ground_truth data/gold_sample.csv

# Classify custom ingredient list
python diet_classifiers.py --ingredients "almond flour, erythritol, egg whites"
````

Or via Docker:

```bash
./run_pipeline.sh       # End-to-end build + run
```

---

## ðŸ’¡ Design Principles

* âœ… **No training? Still usable.** Rule-based fallback ensures predictions even if ML fails.
* âœ… **Weak labels? Strong pipeline.** Ensemble softens rule noise with learned patterns.
* âœ… **Cachable & restart-safe.** Embeddings, models, predictions all memoized with backup.
* âœ… **Containerized deployment.** Three Docker services (CLI, notebook, web/API).
* âœ… **Resilient against partial data.** Works with missing ingredients, broken photos, or sparse recipes.

---

## ðŸ§ª Robustness & Recovery

* ML, vectorizer, and image embeddings are cached with `.npy` or `.pkl` backups
* If cache is corrupted or missing â†’ auto-regenerates from source
* Rule-based logic ensures fallback always available
* Embedding pipeline supports restart-safe env guard

---

## ðŸ“¦ Directory Layout

```
.
â”œâ”€â”€ nb/                            # ðŸ““ Jupyter/CLI container
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ diet_classifiers.py    # Diet classification logic (notebook/CLI)
â”‚   â”‚   â”œâ”€â”€ hybrid_classifier.py   # Optional hybrid model
â”‚   â”‚   â””â”€â”€ task.ipynb             # Dev notebook
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt

â”œâ”€â”€ web/                           # ðŸŒ Web/API container
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”‚   â”œâ”€â”€ app.py                 # Flask entrypoint
â”‚   â”‚   â”œâ”€â”€ diet_classifiers.py    # Main pipeline logic
â”‚   â”‚   â”œâ”€â”€ index_data.py          # Optional search support
â”‚   â”‚   â””â”€â”€ init.sh                # CLI entry + startup
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt

â”œâ”€â”€ data/                          # ðŸ“Š Raw and generated files
â”‚   â”œâ”€â”€ usda/                      # USDA CSVs
â”‚   â””â”€â”€ gold_sample.csv            # 100-row hand-labeled test set

â”œâ”€â”€ docker-compose.yml             # Multi-container runner
â”œâ”€â”€ run_pipeline.sh                # One-click script
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ðŸ”– Artifacts Directory

Trained models and vectorizer are persisted here via the host-mounted  
`./artifacts` folder (inside the container at `/app/artifacts`).

After running the training pipeline, youâ€™ll find:

```

artifacts/
â”œâ”€â”€ vectorizer.pkl
â””â”€â”€ models.pkl

````

Ensure your `docker-compose.yml` maps it:

```yaml
services:
  web:
    â€¦
    volumes:
      - ./artifacts:/app/artifacts
      - recipe-data:/usr/src/data
      - ./web/src:/app/web
````


---

## âœ… Feature Matrix

| Feature                           | Status | Notes                              |
| --------------------------------- | ------ | ---------------------------------- |
| Weak supervision via rules        | âœ…      | Regex, USDA carbs, token rules     |
| Image + Text dual domain          | âœ…      | Optional multimodal with ResNet    |
| Caching + restarts                | âœ…      | Backups + smart reuse              |
| Evaluation plots + exports        | âœ…      | ROC, PR, Confusion Matrix, CSV     |
| Ensemble optimization             | âœ…      | Top-N ranking across 6 metrics     |
| Full container setup              | âœ…      | `docker-compose` 3-container setup |
| CLI usage                         | âœ…      | Command-line friendly              |
| API readiness                     | âœ…      | Flask entrypoint included          |
| Logging and debugging             | âœ…      | Color logs + progress tracking     |
| Integration of external knowledge | âœ…      | USDA nutrition database            |

---

## ðŸ› ï¸ Future Improvements

| Feature                                       | Status | Notes                                                                                                                  |
| --------------------------------------------- | ------ | ---------------------------------------------------------------------------------------------------------------------- |
| ðŸ’¡ **Dynamic Ensemble Weighting (per-row)**   | ðŸ”œ     | Logic is implemented, pending evaluation. Will allow better fusion of text/image-only rows using adaptive soft voting. |
| ðŸ’¡ Net-carb detection (fiber, sugar alcohol)  | âŒ      | Enhance numeric validation by subtracting fiber/sugar alcohol from carb totals.                                        |
| ðŸ’¡ Active learning to resolve USDA ambiguity  | âŒ      | Use model uncertainty to suggest human verification.                                                                   |
| ðŸ’¡ UI for human feedback verification loop    | âŒ      | Let users refine silver labels over time.                                                                              |
| ðŸ’¡ Auto-generated model cards and ONNX export | âŒ      | For transparency and deployment readiness.                                                                             |

> âœ… "Dynamic voting is now supported by the ensemble system but **has not yet been used to generate the above results**. An updated run with this optimization is scheduled next."

---

## ðŸ“š References

* USDA FoodData Central (2023)
* Chawla et al., *SMOTE*, JAI 2002
* He et al., *ResNet*, CVPR 2016
* Salton & Buckley, *TF-IDF*, IR 1988

