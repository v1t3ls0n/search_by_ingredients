

# ğŸ¥‘ Keto & Vegan Diet Classifier â€” Full Submission Report

> **Author:** [Guy Vitelson](https://www.linkedin.com/in/guyvitelson/) Â· ğŸ™ [@v1t3ls0n](https://github.com/v1t3ls0n) Â· ğŸ“§ [guyvitelson@gmail.com](mailto:guyvitelson@gmail.com)

**Submission Type:** End-to-End ML System with Docker
**Pipeline Type:** Ingredient-based diet classification with rule-based and ML ensemble models
**Interfaces:** Command-line (CLI), Docker containerized, optional API integration ready

---

Let me know if you want a signature/footer version too (for a PDF or notebook format), or if you'd like the author details repeated at the bottom as well.


## ğŸ§­ Project Overview

The task was to **build a robust, automated diet classification system** capable of labeling recipe ingredient lists as:

* **Keto-friendly** (low-carb)
* **Vegan** (no animal products)

**Constraints:**

* âŒ No labeled training set provided
* âœ… Must support evaluation on a small gold set
* âœ… Must work from ingredient text only (image optional)
* âœ… Must be containerized and runnable by script

We went significantly beyond these requirements:

* Built a **silver-label generation framework** using rules, USDA data, and fallback logic
* Trained multiple ML models and built a **top-N ensemble**
* Integrated a **text + image multimodal mode**
* Implemented full **logging, caching, fallback handling, and model persistence**
* Made the system robust, modular, and CLI-driven

---

## ğŸ”© Pipeline Summary

### 1. **Silver Labeling**

Since no ground-truth was provided, we created our own **weak labels** using:

* Blacklist/whitelist regex for each diet type
* Rule fallback for missing or ambiguous ingredients
* **USDA nutritional matching**: ingredients with >10g carbs are excluded from "keto"
* If USDA fails, we fall back to token normalization (`"egg whites"` â†’ `"egg"`) and retry

This gave us strong enough supervision to train classifiers.

### 2. **Model Training**

We train multiple text-based classifiers:

* Logistic Regression (Softmax)
* Naive Bayes
* Passive-Aggressive
* Ridge Classifier
* SGDClassifier (SVM-like)

Plus optional **image-based embeddings** using ResNet if images exist.

We score all models using:

* F1 Score
* Precision, Recall, Accuracy
* ROC AUC, PR AUC

Then we **build an ensemble of the top-N models** per task (default N=3), optionally adding a weighted rule-based model as a voter.

### 3. **Evaluation**

We evaluate on a **gold set of 100 samples**, computing full metrics and logging performance:

#### Text-Only Model

| Task  | Accuracy | Precision | Recall | F1 Score | ROC AUC | PR AUC |
| ----- | -------- | --------- | ------ | -------- | ------- | ------ |
| Keto  | 0.97     | 0.95      | 0.97   | **0.96** | 0.99    | 0.98   |
| Vegan | 0.98     | 0.97      | 0.97   | **0.97** | 0.99    | 0.98   |

#### Multimodal (Text + Image)

* **Keto** F1: `0.88 â€“ 0.92`
* **Vegan**: Lower, due to sparse image coverage

### 4. **CLI Interface**

Run full training, labeling, prediction, or gold-eval with simple commands:

```bash
python diet_classifiers.py --train --mode both
python diet_classifiers.py --ground_truth /path/to/gold.csv
```

---

## ğŸ’¡ Design Philosophy

This system was built with **clarity and resilience** in mind. Every decision was pragmatic:

* âœ… **Silver labeling mimics real-world weak supervision**: realistic, noisy, but scalable.
* âœ… **Fallbacks** ensure the system is usable even without training (pure rule-mode).
* âœ… **Smart caching** of models and vectorizers means we donâ€™t retrain needlessly.
* âœ… **Logging-first** design ensures easy debugging.
* âœ… **Dockerized 3-container setup** ensures reproducibility and isolation.

---

## ğŸ§ª Known Limitations

* The **gold set is small** (\~100 samples), so while results are strong, thereâ€™s statistical variance.
* **Image embeddings** are underutilized, but ready for scale â€” the pipeline is designed to absorb better coverage if image data improves.
* No formal **unit tests** (time constraints), but the system includes deep assertions, data validation, and logging at every stage. Unit tests would be next.

---

## ğŸ› ï¸ File Structure (Dockerized)

```bash
.
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ diet_classifiers.py         # Main pipeline script
â”‚   â”œâ”€â”€ app.py                      # CLI & API handler
â”‚   â”œâ”€â”€ index_data.py               # Indexing helpers
â”‚   â””â”€â”€ utils/                      # Shared tools
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ gold.csv                    # Gold-labeled recipes
â”‚   â”œâ”€â”€ usda_cache.json             # Cached nutritional info
â”‚   â””â”€â”€ vectorizer.pkl / models.pkl# Saved ML pipeline
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ run_pipeline.sh                # One-click execution
```

---

## âœ… Features Implemented vs Task Requirements

| Feature                            | Implemented | Notes                                 |
| ---------------------------------- | ----------- | ------------------------------------- |
| Labeling via domain knowledge      | âœ…           | Regex + USDA + fallbacks              |
| Model training from weak labels    | âœ…           | Multiple models + ensemble            |
| Small-scale evaluation on gold set | âœ…           | Detailed metrics + caveats            |
| CLI or API                         | âœ…           | Full CLI, API-ready                   |
| Containerized                      | âœ…           | Full docker-compose 3-container setup |
| Text-only support                  | âœ…           | Primary mode                          |
| Image support (optional)           | âœ…           | Can enrich with images                |
| Model saving + reloading           | âœ…           | Vectorizer + models cached            |
| Logging                            | âœ…           | Verbose, color-coded, robust          |
| Caching                            | âœ…           | Smart cache of embeddings & results   |

---

## ğŸ§  Final Thoughts

This is a robust, modular, and scalable weakly-supervised classification system â€” designed to work **in real conditions**, not just in theory. The ensemble structure, USDA lookup integration, and rule fallbacks ensure it wonâ€™t break under noisy data or missing values.

It's battle-tested in containers, CLI-friendly, and can be improved incrementally with better data or new models.

