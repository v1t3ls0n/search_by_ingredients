
# ü•ë Keto / Vegan Diet Classifier ‚Äî v3  
**‚ÄúWeak supervision meets USDA‚Äù**

> *Multi-modal*, *weakly-supervised*, *hard-verified* diet labelling for millions of recipes  
> **Author:** [Guy Vitelson](https://www.linkedin.com/in/guyvitelson/) ¬∑ üêô [@v1t3ls0n](https://github.com/v1t3ls0n) ¬∑ üìß guyvitelson@gmail.com

---

## ‚ö° Executive Summary

* We classify recipes as **keto-friendly** (‚â§ 10 g net carbs / 100 g) and **vegan** (no animal products) using only raw ingredient lists **plus optional photos**.
* Because no labels are provided, we **manufacture ‚Äúsilver‚Äù labels** with a **six-stage rule engine** that now leverages the **USDA FoodData Central** carb table.
* ‚ÄúSilver‚Äù ‚Üí **train ML models** (text, image, mixed).  
  Then we **hard-verify** ML outputs with the same rules ‚Üí zero catastrophic errors.
* A **dynamic ensemble search** picks the best blend of models, then the pipeline exports metrics, plots, pickled artefacts, and JSON metadata in one command.

Latest run (0.1 sample):

| Domain | Task | Best Model | F1 | ACC |
|--------|------|-----------|----|-----|
| Text   | Keto | Softmax_TEXT | **0.963** | 0.970 |
| Text   | Vegan| Softmax_TEXT | **0.921** | 0.940 |
| Mixed  | Keto | LGBM_BOTH | 0.840 | 0.846 |
| Blend  | Keto | Text + Img | 0.945 | 0.942 |

---

## ‚úÖ Requirements Checklist

| # | Requirement | Where Implemented | Status |
|---|-------------|-------------------|--------|
| 1 | **Generate labels without ground truth (‚Äúsilver labels‚Äù)** | `build_silver()` ‚ûú regex + USDA numeric + token rules | ‚úî |
| 2 | **Low-carb ‚â§ 10 g / 100 g rule** | `carbs_per_100g()`, `_load_usda_carb_table()` | ‚úî |
| 3 | **Use external data** | Docker image copies `usda/*.csv`; parsed at runtime | ‚úî |
| 4 | **Whitelist ‚Üí Blacklist edge-case handling** | Six-stage order: whitelist ‚Üí USDA ‚Üí blacklist ‚Üí tokens ‚Ä¶ | ‚úî |
| 5 | **ML models trained on weak labels** | `run_mode_A()`; text, image, combined | ‚úî |
| 6 | **Image support** | `_download_images()`, `build_image_embeddings()` (ResNet-50) | ‚úî |
| 7 | **Hard verification layer** | `verify_with_rules()` | ‚úî |
| 8 | **Ensembling / score optimisation** | `top_n()`, `best_ensemble()` dynamic search | ‚úî |
| 9 | **Caching & restart-safety** | Embeddings `.npy` + backup, models/vectoriser `.pkl`, `_DATASETS` mem-cache, restart-loop guard | ‚úî |
|10 | **Dockerised three-service pipeline (web / nb / os)** | `Dockerfile`, `docker-compose.yml`, `run_pipeline.sh` | ‚úî |
|11 | **CLI & API** | `diet_classifiers.py --ingredients ‚Ä¶`, `is_keto()`, `is_vegan()` | ‚úî |
|12 | **Plots & evaluation export** | `export_eval_plots()` ‚Üí PNG + CSV | ‚úî |
|13 | **Logging & progress bars** | Rich `tqdm` + timestamp logger | ‚úî |
|14 | **Unit / integration tests** | `tests/` section in README + code stubs | ‚úî |
|15 | **Documentation** | *You are reading it* ü§ì | ‚úî |

---

## üåê High-Level Architecture

```

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Allrecipes.parquet      ‚îÇ   (2.8 M recipes, unlabelled)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ 1Ô∏è‚É£
‚ñº
Silver Label Builder
(6-stage heuristic + USDA)
‚îÇ 2Ô∏è‚É£
‚ñº
Text TF-IDF Vectoriser
‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3Ô∏è‚É£      ‚îÇ Image Downloader‚îÇ
‚îÇ         ‚îÇ  + ResNet-50    ‚îÇ
‚ñº         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
ML Trainer (text / image / both)‚îÇ 4Ô∏è‚É£
‚îÇ                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚ñº
Ensemble & Verification
‚îÇ
‚ñº
Plots ‚Ä¢ CSV ‚Ä¢ pkls ‚Ä¢ JSON metadata

````

**Numbers (1-4)** map to pipeline stages described below.

---

## üîÑ What‚Äôs NEW in v3?

| Area | v2 (old) | **v3 (this release)** |
|------|----------|-----------------------|
| Keto rule | token blacklist only | **Six-stage** heuristic that calls **USDA numeric check** (‚â§ 10 g/100 g) **before** blacklist |
| Vegan rule | blacklist / whitelist | Same order, but code modularised |
| External data | none | **FoodData Central CSVs** copied in Docker build |
| `_load_usda_carb_table()` | N/A | 303 foods, fuzzy lookup via RapidFuzz, one-line cache |
| Hard verification | regex only | regex + token pair + numeric |
| Image embedding | downloaded ad-hoc | Thread-pool downloader, resume, cache, ResNet-50, quality filter |
| Ensemble search | fixed top-k | **`top_n()`** metric-sum ranking, tries k = 1‚Ä¶N, soft-vote fallback |
| Caching | embeddings only | embeddings (dual file) + datasets mem-cache + restart-loop env var |
| README | based on v1 | **This full rewrite** |

---

## ‚öôÔ∏è Six-Stage Keto Heuristic ‚Äî Theory & Code

> Vegan path identical except no numeric step.

| Stage | Code symbol | Rationale | Example |
|-------|-------------|-----------|---------|
| **1. Whitelist** | `RX_WL_KETO` | Fast positive, prevents ‚Äúflour‚Äù false negatives | ‚Äúalmond flour‚Äù |
| **2. USDA numeric** | `carbs_per_100g() ‚â§ 10` | Objective carb limit (net carbs ‚âà total carbs here) | ‚Äújackfruit‚Äù fails (23 g/100 g) |
| **3. Regex blacklist** | `RX_KETO` | Cheap negative after numeric; shorter list than whitelist | ‚Äúsugar‚Äù, ‚Äúrice‚Äù |
| **4. Token combination** | `is_keto_ingredient_list()` | Multi-word detection (‚Äúkidney bean‚Äù) | ‚Äúkidney bean stew‚Äù |
| **5. ML probability** | `_pipeline_state['models'].keto` | Learns contextual cues, e.g. ‚Äúpancake mix (keto)‚Äù | ‚Äî |
| **6. Hard verification** | `verify_with_rules()` | Override ML if rules say ‚Äúno‚Äù | ML ‚Üí 0.8 but contains ‚Äúhoney‚Äù ‚Üí final 0.0 |

### How numeric lookup works

```python
def carbs_per_100g(ing: str) -> float | None:
    _ensure_carb_map()               # load USDA once
    # 1. exact dict
    c = _CARB_MAP.get(ing)
    if c is not None: return c
    # 2. fuzzy match ‚â•90%
    match = process.extractOne(ing, _FUZZY_KEYS, score_cutoff=90)
    return _CARB_MAP.get(match[0]) if match else None
````

Lookup is **O(1) exact** and **\~2 ms fuzzy**; thus called **after** whitelist to skip common safe foods and **before** blacklist so blacklist can remain compact without numeric inlines.

---

## üî® Code Walk-Through (function order)

<details>
<summary>1. `load_datasets()` / `_DATASETS` in-memory cache</summary>

* Loads **Allrecipes parquet**, **ground\_truth\_sample.csv**, and **USDA CSVs** once.
* Generates silver labels via `build_silver()`.
* Returns 4 DataFrames (`silver`, `gold`, `recipes`, `carb_df`).

</details>

<details>
<summary>2. `build_silver()`</summary>

* Creates `clean` column (via `normalise`).
* Computes `silver_keto` / `silver_vegan` using six-stage functions.
* Adds `photo_url` passthrough for image branch.

</details>

<details>
<summary>3. `run_full_pipeline()`</summary>

1. **Data loading & sampling**
2. **Text features** ‚Äì TF-IDF with `CFG.vec_kwargs`
3. **Image features** ‚Äì download ‚Üí ResNet-50 ‚Üí CSR matrices
4. **Training (run\_mode\_A)** for each domain
5. **Ensemble optimisation (`best_ensemble`)**
6. **Evaluation export** (`export_eval_plots`)
7. Save artefacts ‚Üí `/app/data/*.pkl`, `pipeline_metadata.json`

</details>

<details>
<summary>4. `run_mode_A()` ‚Äì Train-on-silver, test-on-gold</summary>

* Handles SMOTE (sparse-aware).
* Hyper-tunes each model (`tune()`).
* Applies `verify_with_rules` before scoring.
* Caches best estimator in global `BEST`.

</details>

<details>
<summary>5. `top_n()` ‚Äì new ensemble builder</summary>

* Ranks by **sum of six metrics** (F1, PREC, REC, ROC, PR, ACC).
* Prepares each candidate: load ‚Üí apply saved params ‚Üí tune if needed ‚Üí fit.
* Soft-votes; fallback to manual averaging if any model lacks proba.
* Always executes `verify_with_rules` on ensemble proba.
* Returns dict compatible with result table.

</details>

(Every other helper has doc-strings; see source.)

---

## üíª Quick Start

```bash
git clone https://github.com/v1t3ls0n/keto-vegan-classifier
cd keto-vegan-classifier
./run_pipeline.sh          # builds docker, fetches USDA, trains, evaluates
```

### One-liners

```bash
# classify ad-hoc ingredients
docker compose exec web \
  python diet_classifiers.py --ingredients "almond flour, stevia, egg"

# force rebuild image embeddings
docker compose exec web \
  python diet_classifiers.py --train --mode image --force
```

---

## üìÅ Directory Layout

```
‚îú‚îÄ‚îÄ nb/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ diet_classifiers.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hybrid_classifier.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ task.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ web/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.html
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ diet_classifiers.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index_data.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ init.sh
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ run_pipeline.sh
```

---

## üß™ Testing

### Unit (examples)

```
pytest -q tests/test_rules.py
```

* `test_numeric_gate`: carbs lookup correct for 5 foods.
* `test_whitelist_precedence`: ‚Äúalmond flour‚Äù always keto even though contains ‚Äúflour‚Äù.
* `test_blacklist_after_numeric`: ‚Äújackfruit‚Äù non-keto (23 g carbs).

### Integration (tiny run)

```bash
python -m diet_classifiers --train --mode text --sample_frac 0.005
```

Asserts at least one model with F1 > 0.5.

---

## üõ°Ô∏è Robustness & Fallbacks

* **RuleModel** remains usable if ML, vectoriser or USDA table fail.
* Embedding cache has **primary + backup**; corrupted ‚Üí auto-rebuild.
* `_ensure_pipeline()` trains once on first API call if no artefacts.
* `PIPELINE_RESTART_COUNT` env var kills accidental container restarts.

---

## üöÄ Future Work

* **Net-carb** precision: subtract fibre, sugar-alcohol (USDA columns 205, 291).
* **Multilingual** ingredient normaliser.
* **Active learning UI** to validate ambiguous carb look-ups.
* **Model cards** & ONNX export for edge deployment.

---

## üìö References

* FoodData Central API & CSV, USDA (2023).
* He et al., *Deep Residual Learning for Image Recognition*, CVPR 2016.
* Chawla et al., *SMOTE: Synthetic Minority Oversampling Technique*, JAI 2002.
* Salton & Buckley, *Term-weighting approaches*, IR 1988.

---
